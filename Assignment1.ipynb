{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Jane Austen novels into a list\n",
    "gutenberg_files = glob.glob(os.path.join(os.getcwd(), 'gutenberg', '*.txt'))\n",
    "austen_texts = [Path(file).read_text() for file in gutenberg_files if 'austen' in file]\n",
    "chesterton_texts = [Path(file).read_text() for file in gutenberg_files if 'chesterton' in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Text Processing and Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Regular Expressions for People Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processRegex(texts, regex):\n",
    "    '''\n",
    "    Find all strings that match the first match group in the specified texts \n",
    "    using the specified regex.\n",
    "        \n",
    "    Return the number of occurrences of each matched word sorted from highest\n",
    "    count to lowest.\n",
    "    '''\n",
    "    \n",
    "    # Find all match groups in all texts\n",
    "    matches = []\n",
    "    for text in texts:\n",
    "        matches += [match.group(1) for match in regex.finditer(text)]\n",
    "    \n",
    "    # Count the number of occurrences of each name\n",
    "    match_counts = {}\n",
    "    for match in matches:\n",
    "        match_counts[match] = matches.count(match)\n",
    "        \n",
    "    return {match: count for match, count in sorted(match_counts.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of regexes to match the honorifics: 'Mr', 'Mrs', 'Miss', 'Ms', and 'Dr'\n",
    "english_honorifics_regexes = [\n",
    "    '\\s[mM]r\\.',\n",
    "    '\\s[mM]iss',\n",
    "    '\\s[mM]rs\\.',\n",
    "    '\\s[mM]s\\.',\n",
    "    '\\s[dD]r\\.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex to match names after an honorific\n",
    "name_pre_boundary_regex = ')\\W'\n",
    "name_match_group = '([A-Z][a-z]+(\\s[A-Z][a-z]+)*)'\n",
    "name_post_boundary_regex = '[\\W]?.?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regex string from honorifics\n",
    "honorific_regex_string = '(?:'\n",
    "for index, honorific in enumerate(english_honorifics_regexes):\n",
    "    honorific_regex_string += '(?<='\n",
    "    honorific_regex_string += honorific\n",
    "    honorific_regex_string += ')|' if index < len(english_honorifics_regexes) - 1 else ')'\n",
    "honorific_regex_string += name_pre_boundary_regex\n",
    "honorific_regex_string += name_match_group\n",
    "honorific_regex_string += name_post_boundary_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Honorifics Regex:\n",
      "(?:(?<=\\s[mM]r\\.)|(?<=\\s[mM]iss)|(?<=\\s[mM]rs\\.)|(?<=\\s[mM]s\\.)|(?<=\\s[dD]r\\.))\\W([A-Z][a-z]+(\\s[A-Z][a-z]+)*)[\\W]?.?\n"
     ]
    }
   ],
   "source": [
    "# Print the honorifics regex\n",
    "print('Honorifics Regex:')\n",
    "print(honorific_regex_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the honorifics regex\n",
    "honorific_regex = re.compile(honorific_regex_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all names/number of occurrences in the J. Austen texts using the honorifics regex\n",
    "austen_name_counts = processRegex(austen_texts, honorific_regex)\n",
    "len(austen_name_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Weston': 413,\n",
       " 'Elton': 362,\n",
       " 'Woodhouse': 293,\n",
       " 'Knightley': 282,\n",
       " 'Jennings': 227,\n",
       " 'Dashwood': 204,\n",
       " 'Bates': 138,\n",
       " 'Fairfax': 119,\n",
       " 'Ferrars': 102,\n",
       " 'Palmer': 71,\n",
       " 'Smith': 69,\n",
       " 'Churchill': 65,\n",
       " 'Goddard': 59,\n",
       " 'Cole': 51,\n",
       " 'Perry': 50,\n",
       " 'Taylor': 48,\n",
       " 'Martin': 46,\n",
       " 'Frank Churchill': 43,\n",
       " 'Elliot': 43,\n",
       " 'Willoughby': 38,\n",
       " 'John Knightley': 37,\n",
       " 'Dixon': 36,\n",
       " 'Steeles': 29,\n",
       " 'Steele': 28,\n",
       " 'John Dashwood': 24,\n",
       " 'Campbell': 23,\n",
       " 'Dashwoods': 23,\n",
       " 'Musgroves': 22,\n",
       " 'Hawkins': 18,\n",
       " 'Marianne': 17,\n",
       " 'Suckling': 14,\n",
       " 'Morton': 14,\n",
       " 'Nash': 13,\n",
       " 'Anne': 13,\n",
       " 'Carteret': 12,\n",
       " 'Harris': 10,\n",
       " 'Pratt': 9,\n",
       " 'Grey': 9,\n",
       " 'Wingfield': 8,\n",
       " 'Smallridge': 8,\n",
       " 'Bragge': 7,\n",
       " 'Musgrove': 7,\n",
       " 'Ford': 6,\n",
       " 'Anne Elliot': 6,\n",
       " 'Williams': 6,\n",
       " 'John\\nKnightley': 5,\n",
       " 'Hodges': 5,\n",
       " 'Jenning': 5,\n",
       " 'Knightleys': 4,\n",
       " 'Stokes': 4,\n",
       " 'Hamilton': 4,\n",
       " 'John\\nDashwood': 4,\n",
       " 'Robert Ferrars': 4,\n",
       " 'Donavan': 4,\n",
       " 'Edward': 4,\n",
       " 'Frank\\nChurchill': 3,\n",
       " 'Richardson': 3,\n",
       " 'Robert Martin': 3,\n",
       " 'Wallis': 3,\n",
       " 'Hughes': 3,\n",
       " 'Otway': 3,\n",
       " 'Bickerton': 3,\n",
       " 'Henry Dashwood': 3,\n",
       " 'Brandon': 3,\n",
       " 'Lucy Steele': 3,\n",
       " 'Ellison': 3,\n",
       " 'Edward Ferrars': 3,\n",
       " 'Eltons': 2,\n",
       " 'Jane Fairfax': 2,\n",
       " 'Cox': 2,\n",
       " 'William Cox': 2,\n",
       " 'Coxes': 2,\n",
       " 'Partridge': 2,\n",
       " 'Richard': 2,\n",
       " 'Gilbert': 2,\n",
       " 'Louisa': 2,\n",
       " 'Larolles': 2,\n",
       " 'Lucy': 2,\n",
       " 'Davies': 2,\n",
       " 'Gray': 2,\n",
       " 'Sparks': 2,\n",
       " 'Woodhouses': 1,\n",
       " 'Prince': 1,\n",
       " 'Martins': 1,\n",
       " 'Harriet Smith': 1,\n",
       " 'Smiths': 1,\n",
       " 'Westons': 1,\n",
       " 'Graham': 1,\n",
       " 'Somebody': 1,\n",
       " 'Jane Bates': 1,\n",
       " 'Green': 1,\n",
       " 'Brown': 1,\n",
       " 'Woodhouse Miss Taylor': 1,\n",
       " 'Emma': 1,\n",
       " 'Jeffereys': 1,\n",
       " 'Bird': 1,\n",
       " 'James Cooper': 1,\n",
       " 'Caroline': 1,\n",
       " 'George': 1,\n",
       " 'Arthur': 1,\n",
       " 'George Otway': 1,\n",
       " 'Perrys': 1,\n",
       " 'Coles': 1,\n",
       " 'Churchills': 1,\n",
       " 'Robert\\nMartin': 1,\n",
       " 'Hayters': 1,\n",
       " 'Harville': 1,\n",
       " 'Louisa Musgrove': 1,\n",
       " 'Atkinson': 1,\n",
       " 'Margaret': 1,\n",
       " 'Careys': 1,\n",
       " 'Impudence': 1,\n",
       " 'Rose': 1,\n",
       " 'Simpson': 1,\n",
       " 'Edward\\nFerrars': 1,\n",
       " 'Walker': 1,\n",
       " 'Dennison': 1,\n",
       " 'Clarke': 1,\n",
       " 'Godby': 1,\n",
       " 'Burgess': 1}"
      ]
     },
     "execution_count": 1003,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all of the names found in the Austen texts with their occurrence counts\n",
    "austen_name_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the Austen name counts to a file\n",
    "austen_name_counts_out = os.path.join(os.getcwd(), 'austen_texts_output', 'sorted_name_matches.txt')\n",
    "with open(austen_name_counts_out, 'w') as file:\n",
    "    for index, name in enumerate(austen_name_counts.keys()):\n",
    "        line = str(name.replace('\\n', ' ')) + ' : ' +  str(austen_name_counts[name]) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Weston': 413,\n",
       " 'Elton': 362,\n",
       " 'Woodhouse': 293,\n",
       " 'Knightley': 282,\n",
       " 'Jennings': 227,\n",
       " 'Dashwood': 204,\n",
       " 'Bates': 138,\n",
       " 'Fairfax': 119,\n",
       " 'Ferrars': 102,\n",
       " 'Palmer': 71}"
      ]
     },
     "execution_count": 1005,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top-10 most frequent names in the Austen texts\n",
    "{name:count for name,count in [name for name in austen_name_counts.items()][0:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 1006,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all names/number of occurrences in the G.K. Chesterton texts using the honorifics regex\n",
    "chesterton_name_counts = processRegex(chesterton_texts, honorific_regex)\n",
    "len(chesterton_name_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bull': 65,\n",
       " 'Turnbull': 18,\n",
       " 'Mac': 17,\n",
       " 'Wilkinson': 14,\n",
       " 'Quayle': 12,\n",
       " 'Renard': 11,\n",
       " 'Rome': 7,\n",
       " 'Syme': 6,\n",
       " 'Evan Mac': 5,\n",
       " 'Cumberland Vane': 5,\n",
       " 'James Turnbull': 5,\n",
       " 'Hutton': 5,\n",
       " 'Vane': 4,\n",
       " 'Harrogate': 4,\n",
       " 'Gordon': 3,\n",
       " 'Barlow': 3,\n",
       " 'Watson': 3,\n",
       " 'Drake': 2,\n",
       " 'Lucian Gregory': 2,\n",
       " 'Witherspoon': 2,\n",
       " 'Gabriel Syme': 2,\n",
       " 'Buttons': 2,\n",
       " 'Henry Gordon': 1,\n",
       " 'Price': 1,\n",
       " 'James Douglas': 1,\n",
       " 'Wimpey': 1,\n",
       " 'Kensit': 1,\n",
       " 'Hertz': 1,\n",
       " 'Durand': 1,\n",
       " 'Ethel Harrogate': 1,\n",
       " 'Ethel': 1,\n",
       " 'Aurora Rome': 1,\n",
       " 'Aurora': 1,\n",
       " 'Etta Todd': 1,\n",
       " 'Gregory': 1,\n",
       " 'Chamberlain': 1,\n",
       " 'Tim\\nHealy': 1,\n",
       " 'Chairman': 1,\n",
       " 'Wilks': 1,\n",
       " 'Ratcliffe': 1}"
      ]
     },
     "execution_count": 1007,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all of the names found Chesterton texts with their occurrence counts\n",
    "chesterton_name_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the Chesterton name counts to a file\n",
    "chesterton_name_counts_out = os.path.join(os.getcwd(), 'chesterton_texts_output', 'sorted_name_matches.txt')\n",
    "with open(chesterton_name_counts_out, 'w') as file:\n",
    "    for index, name in enumerate(chesterton_name_counts.keys()):\n",
    "        line = str(name.replace('\\n', ' ')) + ' : ' +  str(chesterton_name_counts[name]) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bull': 65,\n",
       " 'Turnbull': 18,\n",
       " 'Mac': 17,\n",
       " 'Wilkinson': 14,\n",
       " 'Quayle': 12,\n",
       " 'Renard': 11,\n",
       " 'Rome': 7,\n",
       " 'Syme': 6,\n",
       " 'Evan Mac': 5,\n",
       " 'Cumberland Vane': 5}"
      ]
     },
     "execution_count": 1009,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top-10 most frequent names in the Chesterton novels\n",
    "{name:count for name,count in [name for name in chesterton_name_counts.items()][0:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Regular Expressions for Suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of regexes to match the suffixes: '-ing', '-ness', '-able', and '-ous' \n",
    "suffixes = [\n",
    "    'ing',\n",
    "    'ness',\n",
    "    'able',\n",
    "    'ous',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create suffix regex components\n",
    "pre_match_regex = '\\W'\n",
    "pre_suffix_match_regex = '([A-Za-z]+('\n",
    "post_suffix_match_regex = '))\\W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create suffix word match regex\n",
    "suffix_word_match_regex_string = pre_match_regex\n",
    "suffix_word_match_regex_string += pre_suffix_match_regex\n",
    "for index, suffix in enumerate(suffixes):\n",
    "    suffix_word_match_regex_string += '('\n",
    "    suffix_word_match_regex_string += suffix\n",
    "    suffix_word_match_regex_string += ')|' if index < len(suffixes) - 1 else ')'\n",
    "suffix_word_match_regex_string += post_suffix_match_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix word match regex:\n",
      "\\W([A-Za-z]+((ing)|(ness)|(able)|(ous)))\\W\n"
     ]
    }
   ],
   "source": [
    "# Print the suffix word match regex\n",
    "print('Suffix word match regex:')\n",
    "print(suffix_word_match_regex_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the suffix word match regex\n",
    "suffix_word_match_regex = re.compile(suffix_word_match_regex_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Austen text suffix words: 1494\n"
     ]
    }
   ],
   "source": [
    "# Find all words/number of occurrences in the J. Austen texts using the suffix word match regex\n",
    "austen_suffix_word_counts = processRegex(austen_texts, suffix_word_match_regex)\n",
    "print('Unique Austen text suffix words: {}'.format(len(austen_suffix_word_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the Austen suffix word counts to a file\n",
    "austen_suffix_word_counts_out = os.path.join(os.getcwd(), 'austen_texts_output', 'sorted_suffix_word_matches.txt')\n",
    "with open(austen_suffix_word_counts_out, 'w') as file:\n",
    "    for index, name in enumerate(austen_suffix_word_counts.keys()):\n",
    "        line = str(name) + ' : ' +  str(austen_suffix_word_counts[name]) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'being': 735,\n",
       " 'thing': 617,\n",
       " 'nothing': 520,\n",
       " 'having': 292,\n",
       " 'morning': 247,\n",
       " 'going': 238,\n",
       " 'something': 214,\n",
       " 'evening': 194,\n",
       " 'happiness': 171,\n",
       " 'coming': 159}"
      ]
     },
     "execution_count": 1017,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top-10 most frequent words matched in the Austen novels\n",
    "{word:count for word,count in [word for word in austen_suffix_word_counts.items()][0:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Chesterton text suffix words: 1435\n"
     ]
    }
   ],
   "source": [
    "# Find all words/number of occurrences in the G.K. Chesterton texts using the suffix word match regex\n",
    "chesterton_suffix_word_counts = processRegex(chesterton_texts, suffix_word_match_regex)\n",
    "print('Unique Chesterton text suffix words: {}'.format(len(chesterton_suffix_word_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the Chesterton suffix word counts to a file\n",
    "chesterton_suffix_word_counts_out = os.path.join(os.getcwd(), 'chesterton_texts_output', 'sorted_suffix_word_matches.txt')\n",
    "with open(chesterton_suffix_word_counts_out, 'w') as file:\n",
    "    for index, name in enumerate(chesterton_suffix_word_counts.keys()):\n",
    "        line = str(name) + ' : ' +  str(chesterton_suffix_word_counts[name]) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'something': 261,\n",
       " 'thing': 228,\n",
       " 'being': 150,\n",
       " 'looking': 143,\n",
       " 'nothing': 130,\n",
       " 'going': 121,\n",
       " 'table': 111,\n",
       " 'anything': 104,\n",
       " 'evening': 79,\n",
       " 'everything': 78}"
      ]
     },
     "execution_count": 1020,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top-10 most frequent names in the Chesterton novels\n",
    "{word:count for word,count in [word for word in chesterton_suffix_word_counts.items()][0:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Short Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austen text name count: 3268\n",
      "Austen text suffix word count: 13332\n",
      "Austen text token count: 360150\n",
      "Austen text percent unique names of total name count: 3.67%\n",
      "Percent of Austen texts comprised of names: 0.91%\n",
      "Percent of Austen texts comprised of suffix word matches: 3.70%\n"
     ]
    }
   ],
   "source": [
    "# Some Austen text stats\n",
    "austen_name_count = sum(austen_name_counts.values())\n",
    "austen_suffix_word_count = sum(austen_suffix_word_counts.values())\n",
    "tokenized_austen_texts = [len(text.split()) for text in austen_texts]\n",
    "austen_token_count = sum(tokenized_austen_texts)\n",
    "austen_percent_unique_names_to_name_count = (len(austen_name_counts) / austen_name_count) * 100\n",
    "austen_percent_names = (austen_name_count / austen_token_count) * 100\n",
    "austen_percent_suffix_words = (austen_suffix_word_count / austen_token_count) * 100\n",
    "\n",
    "print('Austen text name count: {}'.format(austen_name_count))\n",
    "print('Austen text suffix word count: {}'.format(austen_suffix_word_count))\n",
    "print('Austen text token count: {}'.format(austen_token_count))\n",
    "print('Austen text percent unique names of total name count: {0:.2f}%'.format(austen_percent_unique_names_to_name_count))\n",
    "print('Percent of Austen texts comprised of names: {0:.2f}%'.format(austen_percent_names))\n",
    "print('Percent of Austen texts comprised of suffix word matches: {0:.2f}%'.format(austen_percent_suffix_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chesterton text name count: 215\n",
      "Chesterton text suffix word count: 6867\n",
      "Chesterton text token count: 211179\n",
      "Chesterton text percent unique names of total name count: 18.60%\n",
      "Percent of Chesterton texts that is names: 0.10%\n",
      "Percent of Chesterton texts comprised of suffix word matches: 3.25%\n"
     ]
    }
   ],
   "source": [
    "# Some Chesterton text stats\n",
    "chesterton_name_count = sum(chesterton_name_counts.values())\n",
    "chesterton_suffix_word_count = sum(chesterton_suffix_word_counts.values())\n",
    "tokenized_chesterton_texts = [len(text.split()) for text in chesterton_texts]\n",
    "chesterton_token_count = sum(tokenized_chesterton_texts)\n",
    "chesterton_percent_unique_names_to_name_count = (len(chesterton_name_counts) / chesterton_name_count) * 100\n",
    "chesterton_percent_names = (chesterton_name_count / chesterton_token_count) * 100\n",
    "chesterton_percent_suffix_words = (chesterton_suffix_word_count / chesterton_token_count) * 100\n",
    "\n",
    "print('Chesterton text name count: {}'.format(chesterton_name_count))\n",
    "print('Chesterton text suffix word count: {}'.format(chesterton_suffix_word_count))\n",
    "print('Chesterton text token count: {}'.format(chesterton_token_count))\n",
    "print('Chesterton text percent unique names of total name count: {0:.2f}%'.format(chesterton_percent_unique_names_to_name_count))\n",
    "print('Percent of Chesterton texts that is names: {0:.2f}%'.format(chesterton_percent_names))\n",
    "print('Percent of Chesterton texts comprised of suffix word matches: {0:.2f}%'.format(chesterton_percent_suffix_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the regexes, I first started by creating a list of the match strings--the lists of honorifics and suffixes--and converted each of those strings to standalone regexes. The honorific strings required tampering with, given that they are standalone tokens that may have capitalization on the initial character and may be followed with a period. The suffix strings did not require any modification. After compiling the lists, I opened a regex tester instance at https://regex101.com/r/8LepJe/1/ and began constructing the other components of the regex. I found that the best way to match names preceeded by one of the honorific regexes is to place those regexes in a non-capturing group. Within the initial non-capturing group, the individual regexes can be separated with ORs ('|') and placed in separate positive lookbehind groups so that any one of the honorifics in the list triggers a potential match for the name capture group. Once I had the non-capturing group constructed, I created the name capture group. Initially, I had it capturing only a single name, using capitalization on the first character to trigger the match. I then added an optional second capture group embedded within the first capture group to capture middle and/or last names. This group matches zero or more times. With this regex I was able to get what looks like reasonable results. Little tweaks to regex, like using [a-z] instead of \\w in the name capture group, provided what appears to be more accurate results. The suffix regex was much simpler, but I did notice that my regex can't match successive matches, such as 'adorable cuteness'--only the first word will be matched in this case. I was unable to fix this issue, but such cases are probably unlikely.\n",
    "\n",
    "As for the matches themselves, the Austen texts contain 3268 name matches, comprising 0.91% of all tokens in the Austen texts when the texts are split on whitespace. By comparison, the Chesterton texts contain only 215 name matches, comprising 0.10% of all tokens. I've never read any Chesterton, but I'm guessing that the interactions, and by extension language, in his novels are less formal than in the Jane Austen texts; it may not be that there are fewer names in the Chesterton texts (although that is likely), but fewer names preceeded by honorifics. The Jane Austen texts are also probably more social in focus than the Chesterton texts. \n",
    "\n",
    "For the suffix matches, there's not much to say, but I did notice nearly all of the matches are lower case, never occurring at the beginning of sentences. I find that somewhat surprising--it's easy to think of sentences that begin with words containing one of those suffixes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 N-gram Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Training Set and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Project Gutenberg Selections corpus \n",
    "gutenberg_files = [file for file in gutenberg_files]\n",
    "unk_placeholder = '<UNK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove blank lines and replace new line characters with spaces\n",
    "#\n",
    "# Note: I adapted the first answer at https://stackoverflow.com/questions/64706030/delete-blank-empty-lines-in-text-file-for-python\n",
    "# to remove blank lines and newline characters\n",
    "processed_texts = []\n",
    "\n",
    "for file in gutenberg_files:\n",
    "    with open(file, 'r') as text:\n",
    "        processed_texts.append(' '.join([line.strip() for line in text.read().split('\\n') if line.strip()]))\n",
    "        \n",
    "processed_text = ' '.join(processed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate spaces\n",
    "processed_text = re.sub(' +', ' ', processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the set of unique characters\n",
    "unique_characters = set(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of occurrences for each unique character\n",
    "character_counts = {}\n",
    "\n",
    "for character in unique_characters:\n",
    "    character_counts[character] = processed_text.count(character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 N-gram Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processNGrams(ngrams, text):\n",
    "    '''\n",
    "    Count the unique N-grams in the specified ngrams list, and return\n",
    "    a dictionary containing the unique N-grams and their number of\n",
    "    occurrences in the specified text. The dictionary is sorted by\n",
    "    number of occurrences from greatest to least.\n",
    "    \n",
    "    All instances of the unk_placeholder character in the N-grams\n",
    "    count dictionary are replaced with 'UNK'.\n",
    "    '''\n",
    "    ngram_counts = {}\n",
    "    unique_ngrams = set(ngrams)\n",
    "    \n",
    "    for ngram in unique_ngrams:\n",
    "        ngram_counts[ngram] = text.count(ngram)\n",
    "        \n",
    "    return {ngram:count for ngram,count in sorted(ngram_counts.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceUNK(n_gram_counts, unk_placeholder, unk_threshold):\n",
    "    '''\n",
    "    Replace all ngrams with count values less than or equal to the specified \n",
    "    unk_threshold in the specified n_gram_counts dicitonary with the\n",
    "    specified unk_placeholder. The new UNK value has a count equal to the\n",
    "    sum of the counts of all ngrams that are less than or equal to the \n",
    "    unk_threshold.\n",
    "    '''\n",
    "    unk_count = 0\n",
    "    ngrams_to_delete = []\n",
    "\n",
    "    for ngram in n_gram_counts.keys():\n",
    "        if n_gram_counts[ngram] <= unk_threshold:\n",
    "            unk_count += n_gram_counts[ngram]\n",
    "            ngrams_to_delete.append(ngram)\n",
    "        \n",
    "    for ngram in ngrams_to_delete:\n",
    "        del n_gram_counts[ngram]\n",
    "    \n",
    "    n_gram_counts[unk_placeholder] = unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility variables\n",
    "characters = [character for character in processed_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unigram counts from training set\n",
    "unigrams = [character for character in processed_text]\n",
    "unigram_counts = processNGrams(unigrams, processed_text)\n",
    "replaceUNK(unigram_counts, unk_placeholder, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the unigram counts to a file\n",
    "unigram_counts_out = os.path.join(os.getcwd(), 'n_gram_counts', 'unigram_counts.txt')\n",
    "with open(unigram_counts_out, 'w') as file:\n",
    "    for index, unigram in enumerate(unigram_counts.keys()):\n",
    "        line = \"'\" + str(unigram) + \"' : \" +  str(unigram_counts[unigram]) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bigram counts from training set\n",
    "#\n",
    "# Note: I adapted the first answer at https://stackoverflow.com/questions/26987901/convert-string-in-to-listin-pairs-in-python\n",
    "#       to generate the initial bigrams list\n",
    "bigrams = [x+y for x,y in zip(characters[0:-1], characters[1:])]\n",
    "bigram_counts = processNGrams(bigrams, processed_text)\n",
    "replaceUNK(bigram_counts, unk_placeholder, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the bigram counts to a file\n",
    "bigram_counts_out = os.path.join(os.getcwd(), 'n_gram_counts', 'bigram_counts.txt')\n",
    "with open(bigram_counts_out, 'w') as file:\n",
    "    for index, bigram in enumerate(bigram_counts.keys()):\n",
    "        line = \"'\" + str(bigram) + \"' : \" +  str(bigram_counts[bigram]) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trigram counts from training set\n",
    "trigrams = [x+y+z for x,y,z in zip(characters[0:-1], characters[1:], characters[2:])]\n",
    "trigram_counts = processNGrams(trigrams, processed_text)\n",
    "replaceUNK(trigram_counts, unk_placeholder, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the trigram counts to a file\n",
    "trigram_counts_out = os.path.join(os.getcwd(), 'n_gram_counts', 'trigram_counts.txt')\n",
    "with open(trigram_counts_out, 'w') as file:\n",
    "    for index, trigram in enumerate(trigram_counts.keys()):\n",
    "        line = \"'\" + str(trigram) + \"' : \" +  str(trigram_counts[trigram]) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Character-level Trigram Language Model with Add-1 (Laplace) Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility variables\n",
    "vocabulary_size = len(trigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test_files = glob.glob(os.path.join(os.getcwd(), 'test_data', '*'))\n",
    "test_files_names = [test_file.rsplit('\\\\', 1)[1] for test_file in test_files]\n",
    "test_texts = []\n",
    "for test_file in test_files:\n",
    "    with open(test_file, encoding='utf8') as file:\n",
    "        test_texts.append(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the trigram model using add-1 Laplace smoothing\n",
    "trigram_add_1_model = {bigram: {unigram: 0.0 for unigram in unigram_counts.keys()} for bigram in bigram_counts.keys()}\n",
    "    \n",
    "for bigram in bigram_counts.keys():\n",
    "    for unigram in unigram_counts.keys():\n",
    "        trigram = bigram + unigram\n",
    "        \n",
    "        if bigram == unk_placeholder or unigram == unk_placeholder:\n",
    "            trigram = unk_placeholder\n",
    "        \n",
    "        trigram_count = 0\n",
    "        if trigram in trigram_counts.keys():\n",
    "            trigram_count = trigram_counts[trigram]\n",
    "        \n",
    "        probability = (trigram_count + 1) / (bigram_counts[bigram] + vocabulary_size)\n",
    "        trigram_add_1_model[bigram][unigram] = probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePerplexity(text, model, unique_unigrams, unique_bigrams, unk_placeholder):\n",
    "    '''\n",
    "    Calculate and return the perplexity of the specified text using the specified model.\n",
    "    \n",
    "    The model is a character-level trigram model with probabilities for all possible\n",
    "    trigram combinations from the specified unique_unigrams and unique_bigrams. \n",
    "    \n",
    "    Any unknown characters encountered in the input text are replaced with the specified\n",
    "    unk_placeholder, which corresponds to probabilities in the specified model.\n",
    "    '''\n",
    "    text_characters = [character for character in text]\n",
    "    text_trigrams = [x+y+z for x,y,z in zip(text_characters[0:-1], text_characters[1:], text_characters[2:])]\n",
    "    \n",
    "    trigram_log_probabilities = []\n",
    "    for trigram in text_trigrams:\n",
    "        unigram = trigram[2]\n",
    "        bigram = trigram[0:2]\n",
    "        \n",
    "        if bigram not in unique_bigrams:\n",
    "            bigram = unk_placeholder\n",
    "        if unigram not in unique_unigrams:\n",
    "            unigram = unk_placeholder\n",
    "        \n",
    "        probabilitly = math.log2(model[bigram][unigram])\n",
    "        trigram_log_probabilities.append(probabilitly)\n",
    "        \n",
    "    sum_log_probs = sum(trigram_log_probabilities)\n",
    "    perplexity = 2**(sum_log_probs * (-1/len(text_trigrams)))\n",
    "    \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the perplexities of all test texts using the laplace add-1 model\n",
    "add_1_perplexities = {}\n",
    "for index, text in enumerate(test_texts):\n",
    "    test_file_name = test_files_names[index]\n",
    "    add_1_perplexities[(index, test_file_name)] = calculatePerplexity(text, trigram_add_1_model, unigram_counts.keys(), bigram_counts.keys(), unk_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the perplexity scores to an output file\n",
    "add_1_perplexities_sorted = {file_name:count for file_name,count in sorted(add_1_perplexities.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "add_1_perplexities_out = os.path.join(os.getcwd(), 'trigram_model_outputs', 'add_1_perplexity_scores.txt')\n",
    "with open(add_1_perplexities_out, 'w') as file:\n",
    "    for file_name_tuple in add_1_perplexities_sorted.keys():\n",
    "        line = str(file_name_tuple[1]) + \", \" +  str(add_1_perplexities_sorted[file_name_tuple]) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(464, '4724'): 21.05068067667954,\n",
       " (930, '9420'): 20.852616820135705,\n",
       " (600, '6094'): 20.847864178891193,\n",
       " (355, '3689'): 20.821422960711995,\n",
       " (58, '0597'): 20.810543612792355,\n",
       " (78, '0807'): 20.77016431106617,\n",
       " (604, '6118'): 20.689868163162338,\n",
       " (113, '1186'): 20.614968920033515,\n",
       " (727, '7384'): 20.606308889959358,\n",
       " (203, '2149'): 20.59675519443719,\n",
       " (310, '3182'): 20.57595520092645,\n",
       " (38, '0404'): 20.56852943765711,\n",
       " (746, '7501'): 20.546526154296597,\n",
       " (2, '0028'): 20.526570451431475,\n",
       " (882, '8853'): 20.477483973508388,\n",
       " (186, '1915'): 20.437170876234628,\n",
       " (900, '8978'): 20.36038713863618,\n",
       " (267, '2769'): 20.35442794271941,\n",
       " (814, '8250'): 20.316018420158283,\n",
       " (409, '4208'): 20.311815169450668,\n",
       " (933, '9448'): 20.28902525089808,\n",
       " (921, '9259'): 20.244450200420257,\n",
       " (336, '3441'): 20.192921537059707,\n",
       " (494, '5030'): 20.171372039112097,\n",
       " (626, '6363'): 20.12815669793464,\n",
       " (324, '3329'): 20.108497148120673,\n",
       " (340, '3492'): 20.105766949950333,\n",
       " (541, '5578'): 20.045188630539293,\n",
       " (56, '0563'): 19.96602701159113,\n",
       " (735, '7419'): 19.941259443855127,\n",
       " (172, '1821'): 19.840055367985038,\n",
       " (326, '3348'): 19.82426082397467,\n",
       " (206, '2154'): 19.822895923905946,\n",
       " (914, '9147'): 19.809024248343096,\n",
       " (472, '4791'): 19.80173358441103,\n",
       " (789, '7980'): 19.76647260374516,\n",
       " (632, '6452'): 19.739808985307846,\n",
       " (738, '7444'): 19.70324881673435,\n",
       " (460, '4672'): 19.678201837914703,\n",
       " (773, '7821'): 19.637893626244942,\n",
       " (947, '9568'): 19.618147769399066,\n",
       " (74, '0774'): 19.614848274353445,\n",
       " (173, '1826'): 19.602232527903965,\n",
       " (606, '6140'): 19.59635665965849,\n",
       " (752, '7540'): 19.54664897956927,\n",
       " (483, '4877'): 19.529203529651497,\n",
       " (693, '7017'): 19.497313580440878,\n",
       " (755, '7564'): 19.428198740980747,\n",
       " (49, '0500'): 19.382186341985665,\n",
       " (33, '0355'): 19.171848724432575}"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 50 texts with the highest perplexity scores\n",
    "add_1_highest_perplexities = {file_name:count for file_name,count in sorted(add_1_perplexities.items(), key=lambda item: item[1], reverse=True)[0:50]}\n",
    "add_1_highest_perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4724\n",
      "La durÃ©e de Leader + est supÃ©rieure d'\n",
      "9420\n",
      "Monsieur le Commissaire, je dis surtout \n",
      "6094\n",
      "Monsieur le Commissaire, il est trÃšs im\n",
      "3689\n",
      "C'est prÃ©cisÃ©ment la raison pour laque\n",
      "0597\n",
      "Aujourd' hui, cette position Ã©cologique\n",
      "0807\n",
      "Ce sont les Ãtats les plus grands qui o\n",
      "6118\n",
      "Par consÃ©quent, il faut que les pays qu\n",
      "1186\n",
      "Le lÃ©gislateur n' a pas toujours besoin\n",
      "7384\n",
      "Nous ne souhaitons pas, nous, Ã©cologist\n",
      "2149\n",
      "Refuser la discussion n'a jamais encore \n",
      "3182\n",
      "Il est important que cette Charte soit r\n",
      "0404\n",
      "Monsieur le PrÃ©sident, la question posÃ\n",
      "7501\n",
      "Ã coup sÃ»r, tout le monde admet que le\n",
      "0028\n",
      "La nouvelle situation crÃ©Ã©e par le tra\n",
      "8853\n",
      "Ce sont ces trois facettes qui doivent n\n",
      "1915\n",
      "En particulier, nous veillerons Ã  avoir\n",
      "8978\n",
      "Nous surveillons la situation des droits\n",
      "2769\n",
      "Monsieur le PrÃ©sident, le Parlement eur\n",
      "8250\n",
      "J'ai votÃ© contre la proposition de rÃ©s\n",
      "4208\n",
      "Compte tenu du fait que nous rÃ©duirons \n",
      "9448\n",
      "La consÃ©quence en est que ce n'est pas \n",
      "9259\n",
      "Nous suivons donc de trÃšs prÃšs toute c\n",
      "3441\n",
      "Pour les cinq prochaines annÃ©es, nous, \n",
      "5030\n",
      "Il va sans dire que l'importance du tour\n",
      "6363\n",
      "Au sein de la Commission, des systÃšmes \n",
      "3329\n",
      "Quant au premier point, j'espÃšre viveme\n",
      "3492\n",
      "L'Ã©largissement Ã  l'Europe centrale et\n",
      "5578\n",
      "En ce sens, il est primordial, et c'est \n",
      "0563\n",
      "Le groupe de Ciampi dÃ©signe Ã©galement \n",
      "7419\n",
      "C'est une question que j'ai l'intention \n",
      "1821\n",
      "La raison est la suivante : le sujet con\n",
      "3348\n",
      "Elles ont dÃ©jÃ  des implications sur la\n",
      "2154\n",
      "La Commission se fÃ©licite d'ailleurs de\n",
      "9147\n",
      "Les deux grandes ressources, Ã©troitemen\n",
      "4791\n",
      "Elle aurait permis de distribuer le labe\n",
      "7980\n",
      "Je pense que la confÃ©rence des donateur\n",
      "6452\n",
      "Monsieur le PrÃ©sident, il est certes im\n",
      "7444\n",
      "La catastrophe de l'Erika n'a pas coÃ»tÃ\n",
      "4672\n",
      "Nous pensons que c'est nÃ©cessaire car i\n",
      "7821\n",
      "Comment, dans ces conditions, justifier \n",
      "9568\n",
      "Monsieur le PrÃ©sident, il paraÃ®t lÃ©gi\n",
      "0774\n",
      "Le fait est que notre commission n'a pas\n",
      "1826\n",
      "Ceci me semble indispensable du fait que\n",
      "6140\n",
      "Selon moi, vous tirez alors dans les jam\n",
      "7540\n",
      "Reprise de la session\n",
      "Je dÃ©clare repris\n",
      "4877\n",
      "Selon les estimations de la Commission, \n",
      "7017\n",
      "Le dÃ©bat est clos.\n",
      "Le vote aura lieu de\n",
      "7564\n",
      "Nous ne devons naturellement pas en atte\n",
      "0500\n",
      "Sur le premier point, nous disons trÃšs \n",
      "0355\n",
      "La seule question substantielle qui a Ã©\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the content of the texts with the highest \n",
    "# perplexity scores\n",
    "for test_file_keys in add_1_highest_perplexities.keys():\n",
    "    print(test_file_keys[1])\n",
    "    print(test_texts[test_file_keys[0]][0:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4724',\n",
       " '9420',\n",
       " '6094',\n",
       " '3689',\n",
       " '0597',\n",
       " '0807',\n",
       " '6118',\n",
       " '1186',\n",
       " '7384',\n",
       " '2149',\n",
       " '3182',\n",
       " '0404',\n",
       " '7501',\n",
       " '0028',\n",
       " '8853',\n",
       " '1915',\n",
       " '8978',\n",
       " '2769',\n",
       " '8250',\n",
       " '4208',\n",
       " '9448',\n",
       " '9259',\n",
       " '3441',\n",
       " '5030',\n",
       " '6363',\n",
       " '3329',\n",
       " '3492',\n",
       " '5578',\n",
       " '0563',\n",
       " '7419',\n",
       " '1821',\n",
       " '3348',\n",
       " '2154',\n",
       " '9147',\n",
       " '4791',\n",
       " '7980',\n",
       " '6452',\n",
       " '7444',\n",
       " '4672',\n",
       " '7821',\n",
       " '9568',\n",
       " '0774',\n",
       " '1826',\n",
       " '6140',\n",
       " '7540',\n",
       " '4877',\n",
       " '7017',\n",
       " '7564',\n",
       " '0500',\n",
       " '0355']"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of all French test texts\n",
    "french_text_file_names = [key[1] for key in add_1_highest_perplexities.keys()]\n",
    "french_text_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the names of the French files to an output file\n",
    "french_files_out = os.path.join(os.getcwd(), 'trigram_model_outputs', 'french_file_names.txt')\n",
    "with open(french_files_out, 'w') as file:\n",
    "    for file_name in french_text_file_names:\n",
    "        line = str(file_name) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Character-level Trigram Language Model with Add-k (Laplace) Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the trigram model using add-5 Laplace smoothing\n",
    "trigram_add_5_model = {bigram: {unigram: 0.0 for unigram in unigram_counts.keys()} for bigram in bigram_counts.keys()}\n",
    "    \n",
    "for bigram in bigram_counts.keys():\n",
    "    for unigram in unigram_counts.keys():\n",
    "        trigram = bigram + unigram\n",
    "        \n",
    "        if bigram == unk_placeholder or unigram == unk_placeholder:\n",
    "            trigram = unk_placeholder\n",
    "        \n",
    "        trigram_count = 0\n",
    "        if trigram in trigram_counts.keys():\n",
    "            trigram_count = trigram_counts[trigram]\n",
    "            \n",
    "        probability = (trigram_count + 5) / (bigram_counts[bigram] + (vocabulary_size * 5))\n",
    "        trigram_add_5_model[bigram][unigram] = probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the perplexities of all test texts using the laplace add-5 model\n",
    "add_5_perplexities = {}\n",
    "for index, text in enumerate(test_texts):\n",
    "    test_file_name = test_files_names[index]\n",
    "    add_5_perplexities[(index, test_file_name)] = calculatePerplexity(text, trigram_add_5_model, unigram_counts.keys(), bigram_counts.keys(), unk_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the perplexity scores to an output file\n",
    "add_5_perplexities_sorted = {file_name:count for file_name,count in sorted(add_5_perplexities.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "add_5_perplexities_out = os.path.join(os.getcwd(), 'trigram_model_outputs', 'add_5_perplexity_scores.txt')\n",
    "with open(add_5_perplexities_out, 'w') as file:\n",
    "    for file_name_tuple in add_5_perplexities_sorted.keys():\n",
    "        line = str(file_name_tuple[1]) + \", \" +  str(add_5_perplexities_sorted[file_name_tuple]) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(464, '4724'): 44.13951851490697,\n",
       " (930, '9420'): 43.96918197232693,\n",
       " (355, '3689'): 43.964552021170135,\n",
       " (58, '0597'): 43.935058293248474,\n",
       " (600, '6094'): 43.925177614057645,\n",
       " (78, '0807'): 43.86347721779008,\n",
       " (38, '0404'): 43.54013963209549,\n",
       " (310, '3182'): 43.4936251133351,\n",
       " (203, '2149'): 43.428800955913886,\n",
       " (746, '7501'): 43.366596654497556,\n",
       " (113, '1186'): 43.33648612927491,\n",
       " (727, '7384'): 43.31945284195853,\n",
       " (604, '6118'): 43.3049784123911,\n",
       " (2, '0028'): 43.21236158574669,\n",
       " (186, '1915'): 43.07342963242527,\n",
       " (882, '8853'): 43.060183044024775,\n",
       " (267, '2769'): 43.059497137710196,\n",
       " (900, '8978'): 43.036107059174064,\n",
       " (409, '4208'): 42.946170700288185,\n",
       " (814, '8250'): 42.90231230639869,\n",
       " (933, '9448'): 42.893702841200835,\n",
       " (336, '3441'): 42.77182932665183,\n",
       " (921, '9259'): 42.751747103123954,\n",
       " (324, '3329'): 42.62177780411885,\n",
       " (494, '5030'): 42.4738493748606,\n",
       " (340, '3492'): 42.430568259769075,\n",
       " (626, '6363'): 42.25135952707855,\n",
       " (735, '7419'): 42.215961597109455,\n",
       " (541, '5578'): 42.173482098494574,\n",
       " (172, '1821'): 42.09492493432813,\n",
       " (56, '0563'): 42.094583275557866,\n",
       " (206, '2154'): 42.05076898039645,\n",
       " (914, '9147'): 42.03663658853435,\n",
       " (326, '3348'): 41.947417648738536,\n",
       " (460, '4672'): 41.93426756183106,\n",
       " (789, '7980'): 41.84103059897517,\n",
       " (632, '6452'): 41.840058830504816,\n",
       " (472, '4791'): 41.8103065276499,\n",
       " (74, '0774'): 41.635322944149266,\n",
       " (173, '1826'): 41.6305232022086,\n",
       " (738, '7444'): 41.61829495337092,\n",
       " (693, '7017'): 41.604529050482604,\n",
       " (773, '7821'): 41.44957045251487,\n",
       " (752, '7540'): 41.40482127330732,\n",
       " (483, '4877'): 41.40391506875628,\n",
       " (606, '6140'): 41.39195492884465,\n",
       " (947, '9568'): 41.38423046015384,\n",
       " (755, '7564'): 41.14665898443687,\n",
       " (49, '0500'): 41.078764471082756,\n",
       " (33, '0355'): 40.58267396154372}"
      ]
     },
     "execution_count": 1054,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 50 texts with the highest perplexity scores\n",
    "add_5_highest_perplexities = {file_name:count for file_name,count in sorted(add_5_perplexities.items(), key=lambda item: item[1], reverse=True)[0:50]}\n",
    "add_5_highest_perplexities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Add-1 and Add-5 Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 1 perplexities avg: 12.43\n",
      "add 1 perplexities max: 21.05\n",
      "add 1 perplexities min: 10.73\n"
     ]
    }
   ],
   "source": [
    "# Add 1 model stats\n",
    "add_1_perplexities_avg = sum(add_1_perplexities.values()) / len(add_1_perplexities)\n",
    "add_1_perplexities_max = max(add_1_perplexities.values())\n",
    "add_1_perplexities_min = min(add_1_perplexities.values())\n",
    "add_5_perplexities_avg = sum(add_5_perplexities.values()) / len(add_5_perplexities)\n",
    "add_5_perplexities_max = max(add_5_perplexities.values())\n",
    "add_5_perplexities_min = min(add_5_perplexities.values())\n",
    "\n",
    "print('add 1 perplexities avg: {0:.2f}'.format(add_1_perplexities_avg))\n",
    "print('add 1 perplexities max: {0:.2f}'.format(add_1_perplexities_max))\n",
    "print('add 1 perplexities min: {0:.2f}'.format(add_1_perplexities_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 5 perplexities avg: 24.05\n",
      "add 5 perplexities max: 44.14\n",
      "add 5 perplexities min: 20.67\n"
     ]
    }
   ],
   "source": [
    "# Add 5 model stats\n",
    "add_5_perplexities_avg = sum(add_5_perplexities.values()) / len(add_5_perplexities)\n",
    "add_5_perplexities_max = max(add_5_perplexities.values())\n",
    "add_5_perplexities_min = min(add_5_perplexities.values())\n",
    "\n",
    "print('add 5 perplexities avg: {0:.2f}'.format(add_5_perplexities_avg))\n",
    "print('add 5 perplexities max: {0:.2f}'.format(add_5_perplexities_max))\n",
    "print('add 5 perplexities min: {0:.2f}'.format(add_5_perplexities_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the add-1 and add-5 model statistics above, the add-1 model has a lower average perplexity score than the add-5 model, indicating that the add-1 model more accurately predicts the trigram distributions of the test texts. While this is unintuitive--usually Laplace smoothing with a greater value of k moves less of the probability mass from very likely n-grams to very unlikely n-grams, producing lower perplexity scores for models with large numbers of zero/low probability cases--the way UNK values are handled in these models may have affected the results. The UNK count for the trigram training set counts is very high (19960 to be exact), and this causes large probabilities to be assigned to low probability trigrams. This especially affects the perplexity scoring for the French language texts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
